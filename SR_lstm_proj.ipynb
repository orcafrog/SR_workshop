{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vsS40o-YeIv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "_bi4KM_qZMJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMMeKCZea1uQ",
        "outputId": "28246cc0-5645-49b0-cb40-f7a5a6dd3aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>EDA</b><br>\n",
        "use SR_storck_data.csv"
      ],
      "metadata": {
        "id": "luX9l0-ubl_X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4EgdaAIQd6Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Model engineering</h2>\n",
        "<b>Modifying model</b>"
      ],
      "metadata": {
        "id": "YuLTi4k6d6hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,num_layers=num_layers, batch_first=True,dropout = 0.25)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device))\n",
        "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device))\n",
        "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        out = self.fc(h_out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "Lt-2Vs85bfbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 500\n",
        "learning_rate = 1e-3\n",
        "input_size = 1\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_classes = 1\n",
        "history = np.zeros((0,5))"
      ],
      "metadata": {
        "id": "Fk87BFdUc1cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
        "lstm.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UT6ucCzdYm7",
        "outputId": "112d4aed-098f-40d1-822f-af6f4a2b86ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (lstm): LSTM(1, 512, batch_first=True, dropout=0.25)\n",
              "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=500,factor =0.5 ,min_lr=1e-7, eps=1e-08)"
      ],
      "metadata": {
        "id": "lGKo4mX0dgbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history):\n",
        "    base_epochs = len(history)\n",
        "    for epoch in range(base_epochs, num_epochs+base_epochs):\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        val_loss = 0\n",
        "        val_acc = 0\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for inputs, labels in tqdm_notebook(train_loader):\n",
        "            count += len(labels)\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "            train_acc += (predicted == labels).sum().item()\n",
        "\n",
        "            avg_train_loss = train_loss / count\n",
        "            avg_train_acc = train_acc / count\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for inputs, labels in test_loader:\n",
        "            count += len(labels)\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "            val_acc += (predicted == labels).sum().item()\n",
        "\n",
        "            avg_val_loss = val_loss / count\n",
        "            avg_val_acc = val_acc / count\n",
        "\n",
        "        print (f'Epoch [{(epoch+1)}/{num_epochs+base_epochs}], loss: {avg_train_loss:.5f} acc: {avg_train_acc:.5f} val_loss: {avg_val_loss:.5f}, val_acc: {avg_val_acc:.5f}')\n",
        "        item = np.array([epoch+1, avg_train_loss, avg_train_acc, avg_val_loss, avg_val_acc])\n",
        "        history = np.vstack((history, item))\n",
        "    return history"
      ],
      "metadata": {
        "id": "53tmP7ved3JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_seed(seed=123):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "p2z78MZWfcZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hv4Exjqjftl4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}